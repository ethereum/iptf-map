---
title: "Vendor: OpenTMP LLM"
status: draft
---

# State Labs – OpenTMP LLM (Collaborative Private AI)

## What it is
OpenTMP LLM is a distributed edge AI training and inference framework designed for privacy-preserving large-language model collaboration.  
It combines federated learning and multi-party computation (MPC-FL) to keep data local while enabling encrypted aggregation and joint model updates.  
It powers collaborative, effcient, secure, and governable AI training across distributed environments.

## Fits with patterns (names only)
- Federated Learning  
- Collaborative AI  
- Secure Inference  

## Not a substitute for
- Centralized AI model training pipelines  
- Non-encrypted data-sharing frameworks  

## Architecture
Distributed AI architecture using MPC-FL with threshold-secure aggregation.  
Supports edge acceleration, model distillation, quantization, and joint model governance.  

## Privacy domains (if applicable)
Collaborative AI / Federated Learning Privacy  

## Enterprise demand and use cases
Organizations requiring confidential AI training and inference—such as healthcare, finance, and government sectors.  

## Technical details
MPC-FL, Distributed Learning, Edge AI Acceleration, SFT, RLHF.  

## Strengths
- Keeps data local during training and inference  
- Enables joint model ownership and governance  
- High efficiency through edge AI optimization  

## Risks and open questions
- Coordination complexity in multi-party settings  
- Trade-offs between model performance and full encryption overhead  

## Links
Website: [https://statelabs.ai](https://statelabs.ai)  
Contact: [joezyx@statelabs.ai](mailto:joezyx@statelabs.ai) | [kyle@statelabs.ai](mailto:kyle@statelabs.ai)
